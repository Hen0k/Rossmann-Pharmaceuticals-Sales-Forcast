{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.fetch_data import DataLoader\n",
    "from src.exploration import Analysis\n",
    "from src.cleaning import CleanDataFrame\n",
    "from src.visualization import Plotters\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default = \"svg\"\n",
    "\n",
    "\n",
    "cleaner = CleanDataFrame()\n",
    "analyzer = Analysis()\n",
    "plotters = Plotters(w=6, h=4)\n",
    "\n",
    "# pd.options.plotting.backend = 'matplotlib'\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "# plt.rcParams.update({'xtick.labelsize': 'large'})\n",
    "# plt.rcParams.update({'ytick.labelsize': 'large'})\n",
    "plt.rcParams.update({'legend.fontsize': 24})\n",
    "%matplotlib inline\n",
    "# plt.rcParams.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DataLoaderLogger - INFO - DVC: CSV file read with path: data/merged/train.csv | version: merged_v1 | from: ../\n",
      "DataLoaderLogger - INFO - DVC: CSV file read with path: data/merged/test.csv | version: merged_v1 | from: ../\n"
     ]
    }
   ],
   "source": [
    "# Then load the raw sales data\n",
    "data_path = 'data/merged/train.csv'\n",
    "version = 'merged_v1'\n",
    "repo = '../'\n",
    "\n",
    "train_df = DataLoader.dvc_get_data(data_path, version, repo)\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "# Finally load the test data\n",
    "data_path = 'data/merged/test.csv'\n",
    "version = 'merged_v1'\n",
    "repo = '../'\n",
    "\n",
    "test_df = DataLoader.dvc_get_data(data_path, version, repo)\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features correlation to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store                        0.005126\n",
       "DayOfWeek                   -0.462125\n",
       "Sales                        1.000000\n",
       "Customers                    0.894711\n",
       "Open                         0.678472\n",
       "Promo                        0.452345\n",
       "SchoolHoliday                0.085124\n",
       "CompetitionDistance         -0.018869\n",
       "CompetitionOpenSinceMonth   -0.028257\n",
       "CompetitionOpenSinceYear     0.012659\n",
       "Promo2                      -0.091040\n",
       "Promo2SinceWeek             -0.044143\n",
       "Promo2SinceYear             -0.091056\n",
       "Year                         0.023519\n",
       "Month                        0.048768\n",
       "WeekOfYear                   0.052946\n",
       "SalesPerCustomer             0.186581\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.corr()[\"Sales\"]#.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41088 entries, 0 to 41087\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   Id                         41088 non-null  int64         \n",
      " 1   Store                      41088 non-null  int64         \n",
      " 2   DayOfWeek                  41088 non-null  int64         \n",
      " 3   Date                       41088 non-null  datetime64[ns]\n",
      " 4   Open                       41077 non-null  float64       \n",
      " 5   Promo                      41088 non-null  int64         \n",
      " 6   StateHoliday               41088 non-null  object        \n",
      " 7   SchoolHoliday              41088 non-null  int64         \n",
      " 8   StoreType                  41088 non-null  object        \n",
      " 9   Assortment                 41088 non-null  object        \n",
      " 10  CompetitionDistance        41088 non-null  float64       \n",
      " 11  CompetitionOpenSinceMonth  25872 non-null  float64       \n",
      " 12  CompetitionOpenSinceYear   25872 non-null  float64       \n",
      " 13  Promo2                     41088 non-null  int64         \n",
      " 14  Promo2SinceWeek            41088 non-null  float64       \n",
      " 15  Promo2SinceYear            41088 non-null  float64       \n",
      " 16  PromoInterval              41088 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(6), int64(6), object(4)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of Customer has the highes correlation with the Sales, but we don't have that in our test data. So, first I will filter the columns that are in my test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 22\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "test_colunns = set(test_df.columns)\n",
    "train_columns = set(train_df.columns)\n",
    "print(len(test_colunns), len(train_columns))\n",
    "common_columns = test_colunns.intersection(train_columns)\n",
    "print(len(common_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count    Dtype         \n",
      "---  ------                     --------------    -----         \n",
      " 0   Store                      1017209 non-null  int64         \n",
      " 1   DayOfWeek                  1017209 non-null  int64         \n",
      " 2   Date                       1017209 non-null  datetime64[ns]\n",
      " 3   Sales                      1017209 non-null  int64         \n",
      " 4   Customers                  1017209 non-null  int64         \n",
      " 5   Open                       1017209 non-null  int64         \n",
      " 6   Promo                      1017209 non-null  int64         \n",
      " 7   StateHoliday               1017209 non-null  object        \n",
      " 8   SchoolHoliday              1017209 non-null  int64         \n",
      " 9   StoreType                  1017209 non-null  object        \n",
      " 10  Assortment                 1017209 non-null  object        \n",
      " 11  CompetitionDistance        1017209 non-null  float64       \n",
      " 12  CompetitionOpenSinceMonth  693861 non-null   float64       \n",
      " 13  CompetitionOpenSinceYear   693861 non-null   float64       \n",
      " 14  Promo2                     1017209 non-null  int64         \n",
      " 15  Promo2SinceWeek            1017209 non-null  float64       \n",
      " 16  Promo2SinceYear            1017209 non-null  float64       \n",
      " 17  PromoInterval              1017209 non-null  object        \n",
      " 18  Year                       1017209 non-null  int64         \n",
      " 19  Month                      1017209 non-null  int64         \n",
      " 20  WeekOfYear                 1017209 non-null  int64         \n",
      " 21  SalesPerCustomer           844340 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(11), object(4)\n",
      "memory usage: 170.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Assortment',\n",
       " 'CompetitionDistance',\n",
       " 'CompetitionOpenSinceMonth',\n",
       " 'CompetitionOpenSinceYear',\n",
       " 'Date',\n",
       " 'DayOfWeek',\n",
       " 'Open',\n",
       " 'Promo',\n",
       " 'Promo2',\n",
       " 'Promo2SinceWeek',\n",
       " 'Promo2SinceYear',\n",
       " 'PromoInterval',\n",
       " 'SchoolHoliday',\n",
       " 'StateHoliday',\n",
       " 'Store',\n",
       " 'StoreType'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are the columns that are not included. Other than the Customer column, the other will be recreated next. I'm just removing them the data, to help me test the pre-processing pipeline I am building.\n",
    "\n",
    "- Raw data comes in\n",
    "- Feature engineering\n",
    "- Droping columns\n",
    "- Encoding categoricals\n",
    "- Scalling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Customers', 'Month', 'Sales', 'SalesPerCustomer', 'WeekOfYear', 'Year'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns.difference(test_colunns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    assert \"Date\" in df.columns\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['WeekOfYear'] = df['Date'].dt.isocalendar().week\n",
    "    df['is_month_end'] = df['Date'].dt.is_month_end\n",
    "    df['is_month_start'] = df['Date'].dt.is_month_start\n",
    "    df['is_quarter_end'] = df['Date'].dt.is_quarter_end\n",
    "    df['is_quarter_start'] = df['Date'].dt.is_quarter_start\n",
    "    df['is_year_end'] = df['Date'].dt.is_year_end\n",
    "    df['is_year_start'] = df['Date'].dt.is_year_start\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of days to holiday,\n",
    "number of days after holiday\n",
    "\n",
    "These should be some type of cumilative sum and differnce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = train_df.query(\"StateHoliday in ['a', 'b', 'c']\")['Date'].dt.date.unique()\n",
    "holidays.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the holiday dates, I need a function that takes in a date, then tells me it's distance on both dxns for the closest holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(date):\n",
    "    \"\"\"uses a sorted list of dates to get the neighboring \n",
    "    dates for a date. \n",
    "    \"\"\"\n",
    "    date = pd.to_datetime(date)\n",
    "    original_year = None\n",
    "    if date.year >= holidays[-1].year:\n",
    "        original_year = date.year\n",
    "        # Assume the date given is in 2014\n",
    "        date = pd.to_datetime(f\"2014-{date.month}-{date.day}\")\n",
    "    previous, upcoming = None, None\n",
    "    for i, d in enumerate(holidays):\n",
    "        if d >= date.date():\n",
    "            previous = holidays[i-1]\n",
    "            upcoming = holidays[i]\n",
    "            if original_year:\n",
    "                print(\"Changed\")\n",
    "                previous = pd.to_datetime(\n",
    "                    f\"{original_year}-{previous.month}-{previous.day}\")\n",
    "                upcoming = pd.to_datetime(\n",
    "                    f\"{original_year}-{upcoming.month}-{upcoming.day}\")\n",
    "            else: print(\"Not change\")\n",
    "            return previous, upcoming\n",
    "\n",
    "\n",
    "def get_holiday_distances(date) -> list[int, int]:\n",
    "    \"\"\"takes in a date, then tells me it's distance on both dxns for the closest holiday\"\"\"\n",
    "    previous, upcoming = get_neighbors(date)\n",
    "    try:\n",
    "        after_holiday = date - previous\n",
    "    except:\n",
    "        print(previous, date, type(previous), type(date))\n",
    "    to_next_holiday = upcoming - date\n",
    "    \n",
    "    return after_holiday, to_next_holiday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our helper function, Let's use them an create the two new columns\n",
    "\n",
    "Create the columns with empty value.\n",
    "\n",
    "iterate over the unique dates and calculate the distances\n",
    "\n",
    "Then replace the coresponding empiy values with the distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_holiday_distance_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['DistanceToNextHoliay'] = pd.NA\n",
    "    df['DistanceFromPrevHoliay'] = pd.NA\n",
    "    unique_dates = df.Date.unique()\n",
    "    p = type(unique_dates[0])\n",
    "    for date in unique_dates:\n",
    "        after_holiday, to_next_holiday = get_holiday_distances(date)\n",
    "        indecies = df[df['Date'] == date].index\n",
    "        df.loc[indecies, 'DistanceToNextHoliay'] = to_next_holiday\n",
    "        df.loc[indecies, 'DistanceFromPrevHoliay'] = after_holiday\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "Changed\n",
      "2014-12-26 2014-12-31T00:00:00.000000000 <class 'datetime.date'> <class 'numpy.datetime64'>\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' cannot use operands with types dtype('O') and dtype('<M8[ns]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb#ch0000025?line=0'>1</a>\u001b[0m preped \u001b[39m=\u001b[39m create_holiday_distance_cols(train_df)\n",
      "\u001b[1;32m/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb Cell 21'\u001b[0m in \u001b[0;36mcreate_holiday_distance_cols\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb#ch0000023?line=4'>5</a>\u001b[0m p \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(unique_dates[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb#ch0000023?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m date \u001b[39min\u001b[39;00m unique_dates:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb#ch0000023?line=6'>7</a>\u001b[0m     after_holiday, to_next_holiday \u001b[39m=\u001b[39m get_holiday_distances(date)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb#ch0000023?line=7'>8</a>\u001b[0m     indecies \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m date]\u001b[39m.\u001b[39mindex\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb#ch0000023?line=8'>9</a>\u001b[0m     df\u001b[39m.\u001b[39mloc[indecies, \u001b[39m'\u001b[39m\u001b[39mDistanceToNextHoliay\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m to_next_holiday\n",
      "\u001b[1;32m/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb Cell 19'\u001b[0m in \u001b[0;36mget_holiday_distances\u001b[0;34m(date)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb#ch0000021?line=29'>30</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb#ch0000021?line=30'>31</a>\u001b[0m     \u001b[39mprint\u001b[39m(previous, date, \u001b[39mtype\u001b[39m(previous), \u001b[39mtype\u001b[39m(date))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb#ch0000021?line=31'>32</a>\u001b[0m to_next_holiday \u001b[39m=\u001b[39m upcoming \u001b[39m-\u001b[39;49m date\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hat/dev-env/10Acadamy/week_3/Rossmann-Pharmaceuticals-Sales-Forcast/notebooks/preprocessing.ipynb#ch0000021?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m after_holiday, to_next_holiday\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'subtract' cannot use operands with types dtype('O') and dtype('<M8[ns]')"
     ]
    }
   ],
   "source": [
    "preped = create_holiday_distance_cols(train_df)\n",
    "    \n",
    "# get_neighbors(my_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new date 2014-08-08 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Timestamp('2022-06-19 00:00:00'), Timestamp('2022-10-03 00:00:00'))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_neighbors(pd.to_datetime(\"2022-8-8\").date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays[-1].year == my_date.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae17cd3bd788a94320e0d05b6452017a9651648b673e7b352c316aae5e41a4d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
