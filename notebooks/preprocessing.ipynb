{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.fetch_data import DataLoader\n",
    "from src.exploration import Analysis\n",
    "from src.cleaning import CleanDataFrame\n",
    "from src.visualization import Plotters\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default = \"svg\"\n",
    "\n",
    "\n",
    "cleaner = CleanDataFrame()\n",
    "analyzer = Analysis()\n",
    "plotters = Plotters(w=6, h=4)\n",
    "\n",
    "# pd.options.plotting.backend = 'matplotlib'\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "# plt.rcParams.update({'xtick.labelsize': 'large'})\n",
    "# plt.rcParams.update({'ytick.labelsize': 'large'})\n",
    "plt.rcParams.update({'legend.fontsize': 24})\n",
    "%matplotlib inline\n",
    "# plt.rcParams.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DataLoaderLogger - INFO - DVC: CSV file read with path: data/merged/train.csv | version: merged_v1 | from: ../\n",
      "DataLoaderLogger - INFO - DVC: CSV file read with path: data/merged/test.csv | version: merged_v1 | from: ../\n"
     ]
    }
   ],
   "source": [
    "# Then load the raw sales data\n",
    "data_path = 'data/merged/train.csv'\n",
    "version = 'merged_v1'\n",
    "repo = '../'\n",
    "\n",
    "train_df = DataLoader.dvc_get_data(data_path, version, repo)\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "# Finally load the test data\n",
    "data_path = 'data/merged/test.csv'\n",
    "version = 'merged_v1'\n",
    "repo = '../'\n",
    "\n",
    "test_df = DataLoader.dvc_get_data(data_path, version, repo)\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features correlation to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store                        0.005126\n",
       "DayOfWeek                   -0.462125\n",
       "Sales                        1.000000\n",
       "Customers                    0.894711\n",
       "Open                         0.678472\n",
       "Promo                        0.452345\n",
       "SchoolHoliday                0.085124\n",
       "CompetitionDistance         -0.018869\n",
       "CompetitionOpenSinceMonth   -0.028257\n",
       "CompetitionOpenSinceYear     0.012659\n",
       "Promo2                      -0.091040\n",
       "Promo2SinceWeek             -0.044143\n",
       "Promo2SinceYear             -0.091056\n",
       "Year                         0.023519\n",
       "Month                        0.048768\n",
       "WeekOfYear                   0.052946\n",
       "SalesPerCustomer             0.186581\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.corr()[\"Sales\"]#.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41088 entries, 0 to 41087\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   Id                         41088 non-null  int64         \n",
      " 1   Store                      41088 non-null  int64         \n",
      " 2   DayOfWeek                  41088 non-null  int64         \n",
      " 3   Date                       41088 non-null  datetime64[ns]\n",
      " 4   Open                       41077 non-null  float64       \n",
      " 5   Promo                      41088 non-null  int64         \n",
      " 6   StateHoliday               41088 non-null  object        \n",
      " 7   SchoolHoliday              41088 non-null  int64         \n",
      " 8   StoreType                  41088 non-null  object        \n",
      " 9   Assortment                 41088 non-null  object        \n",
      " 10  CompetitionDistance        41088 non-null  float64       \n",
      " 11  CompetitionOpenSinceMonth  25872 non-null  float64       \n",
      " 12  CompetitionOpenSinceYear   25872 non-null  float64       \n",
      " 13  Promo2                     41088 non-null  int64         \n",
      " 14  Promo2SinceWeek            41088 non-null  float64       \n",
      " 15  Promo2SinceYear            41088 non-null  float64       \n",
      " 16  PromoInterval              41088 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(6), int64(6), object(4)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of Customer has the highes correlation with the Sales, but we don't have that in our test data. So, first I will filter the columns that are in my test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 22\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "test_colunns = set(test_df.columns)\n",
    "train_columns = set(train_df.columns)\n",
    "print(len(test_colunns), len(train_columns))\n",
    "common_columns = test_colunns.intersection(train_columns)\n",
    "print(len(common_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count    Dtype         \n",
      "---  ------                     --------------    -----         \n",
      " 0   Store                      1017209 non-null  int64         \n",
      " 1   DayOfWeek                  1017209 non-null  int64         \n",
      " 2   Date                       1017209 non-null  datetime64[ns]\n",
      " 3   Sales                      1017209 non-null  int64         \n",
      " 4   Customers                  1017209 non-null  int64         \n",
      " 5   Open                       1017209 non-null  int64         \n",
      " 6   Promo                      1017209 non-null  int64         \n",
      " 7   StateHoliday               1017209 non-null  object        \n",
      " 8   SchoolHoliday              1017209 non-null  int64         \n",
      " 9   StoreType                  1017209 non-null  object        \n",
      " 10  Assortment                 1017209 non-null  object        \n",
      " 11  CompetitionDistance        1017209 non-null  float64       \n",
      " 12  CompetitionOpenSinceMonth  693861 non-null   float64       \n",
      " 13  CompetitionOpenSinceYear   693861 non-null   float64       \n",
      " 14  Promo2                     1017209 non-null  int64         \n",
      " 15  Promo2SinceWeek            1017209 non-null  float64       \n",
      " 16  Promo2SinceYear            1017209 non-null  float64       \n",
      " 17  PromoInterval              1017209 non-null  object        \n",
      " 18  Year                       1017209 non-null  int64         \n",
      " 19  Month                      1017209 non-null  int64         \n",
      " 20  WeekOfYear                 1017209 non-null  int64         \n",
      " 21  SalesPerCustomer           844340 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(11), object(4)\n",
      "memory usage: 170.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Assortment',\n",
       " 'CompetitionDistance',\n",
       " 'CompetitionOpenSinceMonth',\n",
       " 'CompetitionOpenSinceYear',\n",
       " 'Date',\n",
       " 'DayOfWeek',\n",
       " 'Open',\n",
       " 'Promo',\n",
       " 'Promo2',\n",
       " 'Promo2SinceWeek',\n",
       " 'Promo2SinceYear',\n",
       " 'PromoInterval',\n",
       " 'SchoolHoliday',\n",
       " 'StateHoliday',\n",
       " 'Store',\n",
       " 'StoreType'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are the columns that are not included. Other than the Customer column, the other will be recreated next. I'm just removing them the data, to help me test the pre-processing pipeline I am building.\n",
    "\n",
    "- Raw data comes in\n",
    "- Feature engineering\n",
    "- Droping columns\n",
    "- Encoding categoricals\n",
    "- Scalling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Customers', 'Month', 'Sales', 'SalesPerCustomer', 'WeekOfYear', 'Year'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns.difference(test_colunns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds date related categorical columns to the dataframe\"\"\"\n",
    "    assert \"Date\" in df.columns\n",
    "    df = create_holiday_distance_cols(df)\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['WeekOfYear'] = df['Date'].dt.isocalendar().week\n",
    "    df['is_month_end'] = df['Date'].dt.is_month_end\n",
    "    df['is_month_start'] = df['Date'].dt.is_month_start\n",
    "    df['is_quarter_end'] = df['Date'].dt.is_quarter_end\n",
    "    df['is_quarter_start'] = df['Date'].dt.is_quarter_start\n",
    "    df['is_year_end'] = df['Date'].dt.is_year_end\n",
    "    df['is_year_start'] = df['Date'].dt.is_year_start\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of days to holiday,\n",
    "number of days after holiday\n",
    "\n",
    "These should be some type of cumilative sum and differnce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = train_df.query(\"StateHoliday in ['a', 'b', 'c']\")['Date'].dt.date.unique()\n",
    "holidays.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the holiday dates, I need a function that takes in a date, then tells me it's distance on both dxns for the closest holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(date):\n",
    "    \"\"\"uses a sorted list of dates to get the neighboring \n",
    "    dates for a date. \n",
    "    \"\"\"\n",
    "    date = pd.to_datetime(date)\n",
    "    original_year = None\n",
    "    if date.year >= holidays[-1].year:\n",
    "        original_year = date.year\n",
    "        # Assume the date given is in 2014\n",
    "        date = pd.to_datetime(f\"2014-{date.month}-{date.day}\")\n",
    "    previous, upcoming = None, None\n",
    "    for i, d in enumerate(holidays):\n",
    "        if d >= date.date():\n",
    "            previous = pd.to_datetime(holidays[i-1])\n",
    "            upcoming = pd.to_datetime(holidays[i])\n",
    "            if original_year:\n",
    "                previous = pd.to_datetime(\n",
    "                    f\"{original_year}-{previous.month}-{previous.day}\")\n",
    "                upcoming = pd.to_datetime(\n",
    "                    f\"{original_year}-{upcoming.month}-{upcoming.day}\")\n",
    "            return previous, upcoming\n",
    "\n",
    "\n",
    "def get_holiday_distances(date) -> list[int, int]:\n",
    "    \"\"\"takes in a date, then tells me it's distance on both dxns for the closest holiday\"\"\"\n",
    "    previous, upcoming = get_neighbors(date)\n",
    "\n",
    "    after_holiday = date - previous\n",
    "\n",
    "    to_next_holiday = upcoming - date\n",
    "\n",
    "    return int(after_holiday.days), int(to_next_holiday.days)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our helper function, Let's use them an create the two new columns\n",
    "\n",
    "Create the columns with empty value.\n",
    "\n",
    "iterate over the unique dates and calculate the distances\n",
    "\n",
    "Then replace the coresponding empiy values with the distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_holiday_distance_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['DistanceToNextHoliay'] = pd.NA\n",
    "    df['DistanceFromPrevHoliay'] = pd.NA\n",
    "    unique_dates = df.Date.unique()\n",
    "    p = type(unique_dates[0])\n",
    "    for date in unique_dates:\n",
    "        after_holiday, to_next_holiday = get_holiday_distances(date)\n",
    "        indecies = df[df['Date'] == date].index\n",
    "        df.loc[indecies, 'DistanceToNextHoliay'] = to_next_holiday\n",
    "        df.loc[indecies, 'DistanceFromPrevHoliay'] = after_holiday\n",
    "    df['DistanceToNextHoliay'] = df['DistanceToNextHoliay'].astype(int)\n",
    "    df['DistanceFromPrevHoliay'] = df['DistanceFromPrevHoliay'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 30 columns):\n",
      " #   Column                     Non-Null Count    Dtype         \n",
      "---  ------                     --------------    -----         \n",
      " 0   Store                      1017209 non-null  int64         \n",
      " 1   DayOfWeek                  1017209 non-null  int64         \n",
      " 2   Date                       1017209 non-null  datetime64[ns]\n",
      " 3   Sales                      1017209 non-null  int64         \n",
      " 4   Customers                  1017209 non-null  int64         \n",
      " 5   Open                       1017209 non-null  int64         \n",
      " 6   Promo                      1017209 non-null  int64         \n",
      " 7   StateHoliday               1017209 non-null  object        \n",
      " 8   SchoolHoliday              1017209 non-null  int64         \n",
      " 9   StoreType                  1017209 non-null  object        \n",
      " 10  Assortment                 1017209 non-null  object        \n",
      " 11  CompetitionDistance        1017209 non-null  float64       \n",
      " 12  CompetitionOpenSinceMonth  693861 non-null   float64       \n",
      " 13  CompetitionOpenSinceYear   693861 non-null   float64       \n",
      " 14  Promo2                     1017209 non-null  int64         \n",
      " 15  Promo2SinceWeek            1017209 non-null  float64       \n",
      " 16  Promo2SinceYear            1017209 non-null  float64       \n",
      " 17  PromoInterval              1017209 non-null  object        \n",
      " 18  Year                       1017209 non-null  int64         \n",
      " 19  Month                      1017209 non-null  int64         \n",
      " 20  WeekOfYear                 1017209 non-null  UInt32        \n",
      " 21  SalesPerCustomer           844340 non-null   float64       \n",
      " 22  DistanceToNextHoliay       1017209 non-null  int64         \n",
      " 23  DistanceFromPrevHoliay     1017209 non-null  int64         \n",
      " 24  is_month_end               1017209 non-null  bool          \n",
      " 25  is_month_start             1017209 non-null  bool          \n",
      " 26  is_quarter_end             1017209 non-null  bool          \n",
      " 27  is_quarter_start           1017209 non-null  bool          \n",
      " 28  is_year_end                1017209 non-null  bool          \n",
      " 29  is_year_start              1017209 non-null  bool          \n",
      "dtypes: UInt32(1), bool(6), datetime64[ns](1), float64(6), int64(12), object(4)\n",
      "memory usage: 189.2+ MB\n"
     ]
    }
   ],
   "source": [
    "preped = generate_columns(train_df)\n",
    "preped.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the new columns. let's recalcuate the correlation and see if they relate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sales                        1.000000\n",
       "Customers                    0.894711\n",
       "Open                         0.678472\n",
       "Promo                        0.452345\n",
       "SalesPerCustomer             0.186581\n",
       "SchoolHoliday                0.085124\n",
       "DistanceFromPrevHoliay       0.056446\n",
       "WeekOfYear                   0.052946\n",
       "Month                        0.048768\n",
       "is_month_end                 0.047112\n",
       "is_quarter_end               0.027899\n",
       "Year                         0.023519\n",
       "DistanceToNextHoliay         0.014620\n",
       "CompetitionOpenSinceYear     0.012659\n",
       "Store                        0.005126\n",
       "is_quarter_start            -0.013222\n",
       "CompetitionDistance         -0.018869\n",
       "is_year_end                 -0.019392\n",
       "CompetitionOpenSinceMonth   -0.028257\n",
       "Promo2SinceWeek             -0.044143\n",
       "is_month_start              -0.053450\n",
       "is_year_start               -0.084589\n",
       "Promo2                      -0.091040\n",
       "Promo2SinceYear             -0.091056\n",
       "DayOfWeek                   -0.462125\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preped.corr()[\"Sales\"].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have these working, I will need to put them inside a class and make calls to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ae17cd3bd788a94320e0d05b6452017a9651648b673e7b352c316aae5e41a4d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
